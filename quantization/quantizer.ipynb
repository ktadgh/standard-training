{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "# load the calibrated model\n",
    "# state_dict = torch.load(\"quant_resnet50-entropy-1024.pth\", map_location=\"cpu\")\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import CalibrationDataReader, create_calibrator, write_calibration_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataReader(CalibrationDataReader):\n",
    "    def __init__(self,\n",
    "                 image_folder,\n",
    "                 width=1024,\n",
    "                 height=1024,\n",
    "                 start_index=0,\n",
    "                 end_index=0,\n",
    "                 stride=1,\n",
    "                 batch_size=1,\n",
    "                 model_path='augmented_model.onnx',\n",
    "                 input_name='data'):\n",
    "        '''\n",
    "        :param image_folder: image dataset folder\n",
    "        :param width: image width\n",
    "        :param height: image height \n",
    "        :param start_index: start index of images\n",
    "        :param end_index: end index of images\n",
    "        :param stride: image size of each data get \n",
    "        :param batch_size: batch size of inference\n",
    "        :param model_path: model name and path\n",
    "        :param input_name: model input name\n",
    "        '''\n",
    "\n",
    "        self.image_folder = image_folder\n",
    "        self.model_path = model_path\n",
    "        self.preprocess_flag = True\n",
    "        self.enum_data_dicts = iter([])\n",
    "        self.datasize = 0\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.start_index = start_index\n",
    "        self.end_index = len(os.listdir(self.image_folder)) if end_index == 0 else end_index\n",
    "        self.stride = stride if stride >= 1 else 1\n",
    "        self.batch_size = batch_size\n",
    "        self.input_name = input_name\n",
    "        self.sess_options = onnxruntime.SessionOptions()\n",
    "        self.sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "        self.sess_options.enable_mem_pattern = False\n",
    "        self.sess_options.use_deterministic_compute = True\n",
    "        self.sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\n",
    "        self.sess_options.enable_cpu_mem_arena = False\n",
    "    def get_dataset_size(self):\n",
    "        return len(os.listdir(self.image_folder))\n",
    "\n",
    "    def get_input_name(self):\n",
    "        if self.input_name:\n",
    "            return\n",
    "        session = onnxruntime.InferenceSession(self.model_path, self.sess_options,providers=['CPUExecutionProvider'])\n",
    "        self.input_name = session.get_inputs()[0].name\n",
    "\n",
    "    def get_next(self):\n",
    "        iter_data = next(self.enum_data_dicts, None)\n",
    "        if iter_data:\n",
    "            return iter_data\n",
    "\n",
    "        self.enum_data_dicts = None\n",
    "        if self.start_index < self.end_index:\n",
    "            if self.batch_size == 1:\n",
    "                data = self.load_serial()\n",
    "            else:\n",
    "                data = self.load_batches()\n",
    "\n",
    "            self.start_index += self.stride\n",
    "            self.enum_data_dicts = iter(data)\n",
    "\n",
    "            return next(self.enum_data_dicts, None)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def load_serial(self):\n",
    "        width = self.width\n",
    "        height = self.width\n",
    "        nchw_data_list, filename_list, image_size_list = self.preprocess_imagenet(self.image_folder, height, width,\n",
    "                                                                                  self.start_index, self.stride)\n",
    "        input_name = self.input_name\n",
    "\n",
    "        data = []\n",
    "        for i in range(len(nchw_data_list)):\n",
    "            nhwc_data = nchw_data_list[i]\n",
    "            file_name = filename_list[i]\n",
    "            data.append({input_name: nhwc_data})\n",
    "        return data\n",
    "\n",
    "    def load_batches(self):\n",
    "        width = self.width\n",
    "        height = self.height\n",
    "        batch_size = self.batch_size\n",
    "        stride = self.stride\n",
    "        input_name = self.input_name\n",
    "\n",
    "        batches = []\n",
    "        for index in range(0, stride, batch_size):\n",
    "            start_index = self.start_index + index\n",
    "            nchw_data_list, filename_list, image_size_list = self.preprocess_imagenet(\n",
    "                self.image_folder, height, width, start_index, batch_size)\n",
    "\n",
    "            if nchw_data_list.size == 0:\n",
    "                break\n",
    "\n",
    "            nchw_data_batch = []\n",
    "            for i in range(len(nchw_data_list)):\n",
    "                nhwc_data = np.squeeze(nchw_data_list[i], 0)\n",
    "                nchw_data_batch.append(nhwc_data)\n",
    "            batch_data = np.concatenate(np.expand_dims(nchw_data_batch, axis=0), axis=0)\n",
    "            data = {input_name: batch_data}\n",
    "\n",
    "            batches.append(data)\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def preprocess_imagenet(self, images_folder, height, width, start_index=0, size_limit=0):\n",
    "        '''\n",
    "        Loads a batch of images and preprocess them\n",
    "        parameter images_folder: path to folder storing images\n",
    "        parameter height: image height in pixels\n",
    "        parameter width: image width in pixels\n",
    "        parameter start_index: image index to start with   \n",
    "        parameter size_limit: number of images to load. Default is 0 which means all images are picked.\n",
    "        return: list of matrices characterizing multiple images\n",
    "        '''\n",
    "        def preprocess_images(input, channels=3, height=1024, width=1024):\n",
    "            image = input.resize((width, height), Image.Resampling.LANCZOS)\n",
    "            input_data = np.asarray(image).astype(np.float32)\n",
    "            if len(input_data.shape) != 2:\n",
    "                input_data = input_data.transpose([2, 0, 1])\n",
    "            else:\n",
    "                input_data = np.stack([input_data] * 3)\n",
    "            mean = np.array([0.079, 0.05, 0]) + 0.406\n",
    "            std = np.array([0.005, 0, 0.001]) + 0.224\n",
    "            for channel in range(input_data.shape[0]):\n",
    "                input_data[channel, :, :] = (input_data[channel, :, :] / 255 - mean[channel]) / std[channel]\n",
    "            return input_data\n",
    "\n",
    "        image_names = os.listdir(images_folder)\n",
    "        image_names.sort()\n",
    "        if size_limit > 0 and len(image_names) >= size_limit:\n",
    "            end_index = start_index + size_limit\n",
    "            if end_index > len(image_names):\n",
    "                end_index = len(image_names)\n",
    "            batch_filenames = [image_names[i] for i in range(start_index, end_index)]\n",
    "        else:\n",
    "            batch_filenames = image_names\n",
    "\n",
    "        unconcatenated_batch_data = []\n",
    "        image_size_list = []\n",
    "\n",
    "        for image_name in batch_filenames:\n",
    "            image_filepath = images_folder + '/' + image_name\n",
    "            img = Image.open(image_filepath)\n",
    "            \n",
    "            image_data = preprocess_images(img)\n",
    "            image_data = np.expand_dims(image_data, 0)\n",
    "            print(f'img.shape = {image_data.shape}')\n",
    "            unconcatenated_batch_data.append(image_data)\n",
    "            image_size_list.append(np.array([img.size[1], img.size[0]], dtype=np.float32).reshape(1, 2))\n",
    "\n",
    "        batch_data = np.concatenate(np.expand_dims(unconcatenated_batch_data, axis=0), axis=0)\n",
    "        return batch_data, batch_filenames, image_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('trt_engine_cache')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = Path('')\n",
    "trt_cache_dir = checkpoint_dir/'trt_engine_cache'\n",
    "trt_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "trt_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import CalibrationDataReader, CalibrationMethod, create_calibrator, write_calibration_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ImageNetDataReader.__init__() missing 1 required positional argument: 'image_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datareader \u001b[38;5;241m=\u001b[39m \u001b[43mImageNetDataReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ImageNetDataReader.__init__() missing 1 required positional argument: 'image_folder'"
     ]
    }
   ],
   "source": [
    "datareader = ImageNetDataReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationDataReaderCV(CalibrationDataReader):\n",
    "    \"\"\"\n",
    "    A subclass of CalibrationDataReader specifically designed for handling\n",
    "    image data for calibration in computer vision tasks. This reader loads,\n",
    "    preprocesses, and provides images for model calibration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img_file_paths, target_sz, input_name='input'):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the CalibrationDataReaderCV class.\n",
    "        \n",
    "        Args:\n",
    "            img_file_paths (list): A list of image file paths.\n",
    "            target_sz (tuple): The target size (width, height) to resize images to.\n",
    "            input_name (str, optional): The name of the input node in the ONNX model. Default is 'input'.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Initialize the base class\n",
    "        \n",
    "        # Initialization of instance variables\n",
    "        self._img_file_paths = img_file_paths\n",
    "        self.input_name = input_name\n",
    "        self.enum = iter(img_file_paths)  # Create an iterator over the image paths\n",
    "        self.target_sz = target_sz\n",
    "        \n",
    "    def get_next(self):\n",
    "        \"\"\"\n",
    "        Retrieves, processes, and returns the next image in the sequence as a NumPy array suitable for model input.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary with a single key-value pair where the key is `input_name` and the value is the\n",
    "                  preprocessed image as a NumPy array, or None if there are no more images.\n",
    "        \"\"\"\n",
    "        \n",
    "        img_path = next(self.enum, None)  # Get the next image path\n",
    "        if not img_path:\n",
    "            return None  # If there are no more paths, return None\n",
    "\n",
    "        # Load the image from the filepath and convert to RGB\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Resize the image to the target size\n",
    "        input_img = resize_img(image, target_sz=self.target_sz, divisor=1)\n",
    "        \n",
    "        # Convert the image to a NumPy array, normalize, and add a batch dimension\n",
    "        input_tensor_np = np.array(input_img, dtype=np.float32).transpose((2, 0, 1))[None] / 255\n",
    "\n",
    "        # Return the image in a dictionary under the specified input name\n",
    "        return {self.input_name: input_tensor_np}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = '/home/ubuntu/transformer-distillation/ps1-self-no-window.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: name 'CalibrationDataReaderCV' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Save path for temporary ONNX model used during calibration process\n",
    "augmented_model_path = \"augmented.onnx\"\n",
    "\n",
    "try:\n",
    "    # Create a calibrator object for the ONNX model.\n",
    "    calibrator = create_calibrator(\n",
    "        model=onnx_file_path, \n",
    "        op_types_to_calibrate=None, \n",
    "        augmented_model_path=augmented_model_path, \n",
    "        calibrate_method=CalibrationMethod.MinMax\n",
    "    )\n",
    "\n",
    "    # Set the execution providers for the calibrator.\n",
    "    calibrator.set_execution_providers([\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\n",
    "\n",
    "    # Initialize the custom CalibrationDataReader object\n",
    "    calibration_data_reader = CalibrationDataReaderCV(img_file_paths=sample_img_paths, \n",
    "                                                      target_sz=target_sz, \n",
    "                                                      input_name=calibrator.model.graph.input[0].name)\n",
    "\n",
    "    # Collect calibration data using the specified data reader.\n",
    "    calibrator.collect_data(data_reader=calibration_data_reader)\n",
    "\n",
    "    # Initialize an empty dictionary to hold the new compute range values.\n",
    "    new_compute_range = {}\n",
    "\n",
    "    # Compute data and update the compute range for each key in the calibrator's data.\n",
    "    for k, v in calibrator.compute_data().data.items():\n",
    "        # Extract the min and max values from the range_value.\n",
    "        v1, v2 = v.range_value\n",
    "        # Convert the min and max values to float and store them in the new_compute_range dictionary.\n",
    "        new_compute_range[k] = (float(v1.item()), float(v2.item()))\n",
    "        \n",
    "    # Write the computed calibration table to the specified directory.\n",
    "    write_calibration_table(new_compute_range, dir=str(trt_cache_dir))\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    # Catch any exceptions that occur during the calibration process.\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# finally:\n",
    "    # Remove temporary ONNX file created during the calibration process\n",
    "    # if augmented_model_path.exists():\n",
    "    #     augmented_model_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageNetDataReader('../input_rotation/testA',width=1024,\n",
    "                            height=1024,start_index=0,end_index=0,\n",
    "                            stride=1,batch_size=1,\n",
    "                            model_path='/home/ubuntu/transformer-distillation/width1.onnx',\n",
    "                            input_name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m onnxruntime.quantization.preprocess --input /home/ubuntu/transformer-distillation/ps1.onnx --output /home/ubuntu/transformer-distillation/width2-pre2.onnx --skip_optimization True --verbose 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m onnxruntime.quantization.preprocess --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking that onnxruntime works on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,3,1024,1024)\n",
    "providers = [\n",
    "    ('CPUExecutionProvider')]\n",
    "\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "sess_options.enable_mem_pattern = False\n",
    "sess_options.use_deterministic_compute = True\n",
    "sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\n",
    "sess_options.enable_cpu_mem_arena = False\n",
    "\n",
    "\n",
    "session = onnxruntime.InferenceSession(\"/home/ubuntu/transformer-distillation/width2-pre.onnx\",sess_options,providers=providers)\n",
    "\n",
    "input_data = input.cpu().numpy().astype(np.float32)\n",
    "ort_inputs = {session.get_inputs()[0].name: input_data}\n",
    "onnx_output = session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to quantize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxruntime.quantization.shape_inference.quant_pre_process('/home/ubuntu/transformer-distillation/ps1.onnx', '/home/ubuntu/transformer-distillation/ps2.onnx', skip_symbolic_shape=False, skip_optimization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape = (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2024-07-23 15:54:42.119576678 [E:onnxruntime:, sequential_executor.cc:516 ExecuteKernel] Non-zero status code returned while running ReduceMax node. Name:'/model/up_levels.2/up_levels.2.0/self_attn/Slice_18_output_0_ReduceMax' Status Message: \u001b[m\n"
     ]
    },
    {
     "ename": "RuntimeException",
     "evalue": "[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running ReduceMax node. Name:'/model/up_levels.2/up_levels.2.0/self_attn/Slice_18_output_0_ReduceMax' Status Message: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mONNX full precision model size (MB):\u001b[39m\u001b[38;5;124m'\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(onnx_model_path)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mONNX quantized model size (MB):\u001b[39m\u001b[38;5;124m'\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(quantized_model_path)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m \u001b[43mquantize_onnx_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/transformer-distillation/ps2.onnx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/transformer-distillation/width2-q.onnx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mquantize_onnx_model\u001b[0;34m(onnx_model_path, quantized_model_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m onnx_opt_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(onnx_model_path)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mquantize_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mquantized_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcalibration_data_reader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mweight_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQuantType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQInt8\u001b[49m\u001b[43m,\u001b[49m\u001b[43mextra_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMatMulConstBOnly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantized model saved to:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquantized_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mONNX full precision model size (MB):\u001b[39m\u001b[38;5;124m'\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(onnx_model_path)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/OMGD/lib/python3.11/site-packages/onnxruntime/quantization/quantize.py:513\u001b[0m, in \u001b[0;36mquantize_static\u001b[0;34m(model_input, model_output, calibration_data_reader, quant_format, op_types_to_quantize, per_channel, reduce_range, activation_type, weight_type, nodes_to_quantize, nodes_to_exclude, use_external_data_format, calibrate_method, extra_options)\u001b[0m\n\u001b[1;32m    503\u001b[0m     model_input \u001b[38;5;241m=\u001b[39m output_path\n\u001b[1;32m    505\u001b[0m calibrator \u001b[38;5;241m=\u001b[39m create_calibrator(\n\u001b[1;32m    506\u001b[0m     Path(model_input),\n\u001b[1;32m    507\u001b[0m     op_types_to_quantize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m     extra_options\u001b[38;5;241m=\u001b[39mcalib_extra_options,\n\u001b[1;32m    512\u001b[0m )\n\u001b[0;32m--> 513\u001b[0m \u001b[43mcalibrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalibration_data_reader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m tensors_range \u001b[38;5;241m=\u001b[39m calibrator\u001b[38;5;241m.\u001b[39mcompute_data()\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_range, TensorsData):\n",
      "File \u001b[0;32m~/anaconda3/envs/OMGD/lib/python3.11/site-packages/onnxruntime/quantization/calibrate.py:366\u001b[0m, in \u001b[0;36mMinMaxCalibrater.collect_data\u001b[0;34m(self, data_reader)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inputs:\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_intermediate_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_intermediate_outputs\n\u001b[1;32m    370\u001b[0m ):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_collected_data()\n",
      "File \u001b[0;32m~/anaconda3/envs/OMGD/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mRuntimeException\u001b[0m: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running ReduceMax node. Name:'/model/up_levels.2/up_levels.2.0/self_attn/Slice_18_output_0_ReduceMax' Status Message: "
     ]
    }
   ],
   "source": [
    "def quantize_onnx_model(onnx_model_path, quantized_model_path):\n",
    "    from onnxruntime.quantization import quantize_static,quantize_dynamic, QuantType\n",
    "    import onnx\n",
    "    onnx_opt_model = onnx.load(onnx_model_path)\n",
    "    quantize_static(onnx_model_path,\n",
    "                     quantized_model_path,\n",
    "                     calibration_data_reader=loader,\n",
    "                     weight_type=QuantType.QInt8,extra_options={'MatMulConstBOnly':True})\n",
    "\n",
    "    print(f\"quantized model saved to:{quantized_model_path}\")\n",
    "    print('ONNX full precision model size (MB):', os.path.getsize(onnx_model_path)/(1024*1024))\n",
    "    print('ONNX quantized model size (MB):', os.path.getsize(quantized_model_path)/(1024*1024))\n",
    "\n",
    "quantize_onnx_model('/home/ubuntu/transformer-distillation/ps2.onnx', '/home/ubuntu/transformer-distillation/width2-q.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxruntime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k-diff-dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
