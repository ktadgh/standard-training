{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Standard Library dependencies\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Import utility functions\n",
    "# from cjm_psl_utils.core import download_file, file_extract\n",
    "# from cjm_pil_utils.core import resize_img, get_img_files\n",
    "from PIL import Image\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Do not truncate the contents of cells and display all rows and columns\n",
    "pd.set_option('max_colwidth', None, 'display.max_rows', None, 'display.max_columns', None)\n",
    "\n",
    "# Import PIL for image manipulation\n",
    "from PIL import Image\n",
    "\n",
    "# Import ONNX dependencies\n",
    "import onnxruntime as ort # Import the ONNX Runtime\n",
    "from onnxruntime.tools.symbolic_shape_infer import SymbolicShapeInference\n",
    "from onnxruntime.quantization import CalibrationDataReader, CalibrationMethod, create_calibrator, write_calibration_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = '/home/ubuntu/transformer-distillation/ps1-self-no-window.onnx'\n",
    "sample_img_paths = ['img_5001.png','img_5002.png']\n",
    "trt_cache_dir = 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationDataReaderCV(CalibrationDataReader):\n",
    "    \"\"\"\n",
    "    A subclass of CalibrationDataReader specifically designed for handling\n",
    "    image data for calibration in computer vision tasks. This reader loads,\n",
    "    preprocesses, and provides images for model calibration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img_file_paths, target_sz, input_name='input'):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the CalibrationDataReaderCV class.\n",
    "        \n",
    "        Args:\n",
    "            img_file_paths (list): A list of image file paths.\n",
    "            target_sz (tuple): The target size (width, height) to resize images to.\n",
    "            input_name (str, optional): The name of the input node in the ONNX model. Default is 'input'.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Initialize the base class\n",
    "        \n",
    "        # Initialization of instance variables\n",
    "        self._img_file_paths = img_file_paths\n",
    "        self.input_name = input_name\n",
    "        self.enum = iter(img_file_paths)  # Create an iterator over the image paths\n",
    "        self.target_sz = target_sz\n",
    "        \n",
    "    def get_next(self):\n",
    "        \"\"\"\n",
    "        Retrieves, processes, and returns the next image in the sequence as a NumPy array suitable for model input.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary with a single key-value pair where the key is `input_name` and the value is the\n",
    "                  preprocessed image as a NumPy array, or None if there are no more images.\n",
    "        \"\"\"\n",
    "        \n",
    "        img_path = next(self.enum, None)  # Get the next image path\n",
    "        if not img_path:\n",
    "            return None  # If there are no more paths, return None\n",
    "\n",
    "        # Load the image from the filepath and convert to RGB\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Resize the image to the target size\n",
    "        input_img = image #resize_img(image, target_sz=self.target_sz, divisor=1)\n",
    "        \n",
    "        # Convert the image to a NumPy array, normalize, and add a batch dimension\n",
    "        input_tensor_np = np.array(input_img, dtype=np.float32).transpose((2, 0, 1))[None] / 255\n",
    "\n",
    "        # Return the image in a dictionary under the specified input name\n",
    "        return {self.input_name: input_tensor_np}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-07-24 13:36:48.805163757 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 650 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.9 s, sys: 3.6 s, total: 48.5 s\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Save path for temporary ONNX model used during calibration process\n",
    "augmented_model_path = onnx_file_path.replace('.onnx', '') + '-augmented.onnx'\n",
    "\n",
    "try:\n",
    "    # Create a calibrator object for the ONNX model.\n",
    "    calibrator = create_calibrator(\n",
    "        model=onnx_file_path, \n",
    "        op_types_to_calibrate=None, \n",
    "        augmented_model_path=augmented_model_path, \n",
    "        calibrate_method=CalibrationMethod.MinMax\n",
    "    )\n",
    "\n",
    "    # Set the execution providers for the calibrator.\n",
    "    calibrator.set_execution_providers([\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\n",
    "\n",
    "    # Initialize the custom CalibrationDataReader object\n",
    "    calibration_data_reader = CalibrationDataReaderCV(img_file_paths=sample_img_paths, \n",
    "                                                      target_sz=1024, \n",
    "                                                      input_name=calibrator.model.graph.input[0].name)\n",
    "\n",
    "    # Collect calibration data using the specified data reader.\n",
    "    calibrator.collect_data(data_reader=calibration_data_reader)\n",
    "\n",
    "    # Initialize an empty dictionary to hold the new compute range values.\n",
    "    new_compute_range = {}\n",
    "\n",
    "    # Compute data and update the compute range for each key in the calibrator's data.\n",
    "    for k, v in calibrator.compute_data().data.items():\n",
    "        # Extract the min and max values from the range_value.\n",
    "        v1, v2 = v.range_value\n",
    "        # Convert the min and max values to float and store them in the new_compute_range dictionary.\n",
    "        new_compute_range[k] = (float(v1.item()), float(v2.item()))\n",
    "        \n",
    "    # Write the computed calibration table to the specified directory.\n",
    "    write_calibration_table(new_compute_range, dir=str(trt_cache_dir))\n",
    "    \n",
    "except Exception as e:\n",
    "    # Catch any exceptions that occur during the calibration process.\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# finally:\n",
    "#     Remove temporary ONNX file created during the calibration process\n",
    "#     if augmented_model_path.exists():\n",
    "#         augmented_model_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/transformer-distillation/cache/calibration.flatbuffers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ubuntu/transformer-distillation/cache/calibration.cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ubuntu/transformer-distillation/cache/calibration.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     0\n",
       "0  /home/ubuntu/transformer-distillation/cache/calibration.flatbuffers\n",
       "1        /home/ubuntu/transformer-distillation/cache/calibration.cache\n",
       "2         /home/ubuntu/transformer-distillation/cache/calibration.json"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(['/home/ubuntu/transformer-distillation/cache/calibration.flatbuffers','/home/ubuntu/transformer-distillation/cache/calibration.cache','/home/ubuntu/transformer-distillation/cache/calibration.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort.get_available_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = 'ps1-self-no-window.onnx'\n",
    "from onnx import shape_inference\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path ='ps1-self-no-window.onnx'\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "# Perform shape inference\n",
    "inferred_model = shape_inference.infer_shapes(model)\n",
    "\n",
    "# Save the inferred model (optional)\n",
    "onnx.save(inferred_model, 'ps1-self-no-window-nothing.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = 'ps1-self-no-window-nothing.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command2 = [\"python\", \"-m\", \"onnxruntime.quantization.preprocess\",\"--input\", onnx_file_path,\"--output\", onnx_file_path]\n",
    "# # Run the command\n",
    "# _ = subprocess.run(command2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import onnx\n",
    "# from onnx import numpy_helper\n",
    "\n",
    "# # Load the ONNX model\n",
    "# model_path = onnx_file_path\n",
    "# model = onnx.load(model_path)\n",
    "\n",
    "# # Print the model's input and output types\n",
    "# def print_value_info(value_info):\n",
    "#     for value in value_info:\n",
    "#         print(f\"Name: {value.name}, Type: {onnx.helper.printable_type(value.type)}\")\n",
    "\n",
    "# # Print the data types of all inputs\n",
    "# print(\"Model Inputs:\")\n",
    "# print_value_info(model.graph.input)\n",
    "\n",
    "# # Print the data types of all outputs\n",
    "# print(\"Model Outputs:\")\n",
    "# print_value_info(model.graph.output)\n",
    "\n",
    "# # Print the data types of all intermediate tensors\n",
    "# print(\"Intermediate Tensors:\")\n",
    "# print_value_info(model.graph.value_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    ('TensorrtExecutionProvider', {\n",
    "        'device_id': 0, # The device ID\n",
    "        'trt_max_workspace_size': 24e9, # Maximum workspace size for TensorRT engine (1e9 ≈ 1GB)\n",
    "        'trt_engine_cache_enable': False, # Enable TensorRT engine caching\n",
    "        'trt_engine_cache_path': str(trt_cache_dir), # Path for TensorRT engine, profile files, and INT8 calibration table\n",
    "        'trt_int8_enable': True, # Enable INT8 mode in TensorRT\n",
    "        'trt_int8_calibration_table_name': 'calibration.flatbuffers', # INT8 calibration table file for non-QDQ models in INT8 mode\n",
    "    })\n",
    "]\n",
    "\n",
    "sess_opt = ort.SessionOptions()\n",
    "sess_opt.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "sess_opt.enable_mem_pattern = False\n",
    "sess_opt.use_deterministic_compute = True\n",
    "sess_opt.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "sess_opt.enable_cpu_mem_arena = False\n",
    "\n",
    "# Load the model and create an InferenceSession\n",
    "session = ort.InferenceSession(onnx_file_path, sess_options=sess_opt, providers=providers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k-diff-dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
